{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# This a CNN code for binary image classification. Please try to modify the code and change the parameters for your own problem"
      ],
      "metadata": {
        "id": "P-Ordn6IBJ5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#If there was any ambiguity at any step, ChatGPT can come to rescue!"
      ],
      "metadata": {
        "id": "w597aIfgF8cn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4XIuJCihd4n"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing images for train and test sets"
      ],
      "metadata": {
        "id": "2Rzh2iSLiG6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Images are rescaled (their pixel values) and \"distoted\" a bit in different ways to avoid overfitting. The image sizes are also set to 64*64. You change/modify any of these ao add to them."
      ],
      "metadata": {
        "id": "Vun5Ckr_CdvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "# If, for instance, you want to classify images of galaxy type A and galaxy type B, there should be\n",
        "# two folders, galaxy_type_A and galaxy_type_B inside the trainin_set folder each containing the corresponnding\n",
        "# images.\n",
        "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "metadata": {
        "id": "-EYVvHg2he56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "metadata": {
        "id": "SbFSgHS4hj2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initializing the CNN"
      ],
      "metadata": {
        "id": "LMslBFBniOKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "6SWKgsmxhnH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding convolution and max pooling"
      ],
      "metadata": {
        "id": "iF75pqh1iV1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ],
      "metadata": {
        "id": "d2OKmOHQhn3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "pJCwsVMfhqBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding additional convolution and max pooling"
      ],
      "metadata": {
        "id": "rUXyEC9lidWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "CT5C9UAChsZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flattenning"
      ],
      "metadata": {
        "id": "iFZfMgGNikk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "u_b5YJkFhvwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inputing the fully connected neural networkk"
      ],
      "metadata": {
        "id": "TCagKvsmiu1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "metadata": {
        "id": "larpff5_hxuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "LoQaHqfNhyZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizitation of the CNN"
      ],
      "metadata": {
        "id": "Vzek7Y-hjFXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "PotxMrcAh3Pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The validation data shown below can be different from the test data (like 70% train, 20 % test and 10% evaluation). Here it is selected to be the same as test set just to show an example."
      ],
      "metadata": {
        "id": "lzGGVoIcDBS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ],
      "metadata": {
        "id": "BbQEtwUnh56_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing section"
      ],
      "metadata": {
        "id": "8s8MqWL6jK3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load and resize image\n",
        "test_image = image.load_img('dataset/single_prediction/test_image_1.jpg', target_size=(64, 64))\n",
        "\n",
        "# Convert to array\n",
        "test_image = image.img_to_array(test_image)\n",
        "\n",
        "# Rescale to match training\n",
        "test_image = test_image / 255.0\n",
        "\n",
        "# Add batch dimension\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "\n",
        "# Make prediction\n",
        "result = cnn.predict(test_image)\n",
        "\n",
        "# Check class indices to make sure that you are interpreting the predictions correctly.\n",
        "print(training_set.class_indices)\n",
        "\n",
        "# Interpret result (assuming you got the class indices correctly for type A and type B classes.)\n",
        "if result[0][0] > 0.5:\n",
        "    prediction = 'type A'\n",
        "else:\n",
        "    prediction = 'type B'\n",
        "\n",
        "print(prediction)"
      ],
      "metadata": {
        "id": "1tnZUr7Uh7rS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}